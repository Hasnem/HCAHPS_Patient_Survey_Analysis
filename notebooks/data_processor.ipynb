{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Missing input file: c:\\Users\\alnem\\OneDrive - Institute for Community Alliances\\Desktop\\Al Nemrawi, Hassan-2-20240821T140221Z-001\\portfolio\\HCAHPS_Patient_Survey_Analysis\\healps_data\\HCAHPS-National.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 223\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m input_files:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m--> 223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing input file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_path, output_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(input_files, output_files):\n\u001b[0;32m    226\u001b[0m     process_hcahps_data(input_path, output_path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Missing input file: c:\\Users\\alnem\\OneDrive - Institute for Community Alliances\\Desktop\\Al Nemrawi, Hassan-2-20240821T140221Z-001\\portfolio\\HCAHPS_Patient_Survey_Analysis\\healps_data\\HCAHPS-National.csv"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Configuration for HCAHPS data processing\n",
    "HCAHPS_CONFIG = {\n",
    "    \"release_period\": \"07_2024\",\n",
    "    \"columns_to_drop\": [\n",
    "        'HCAHPS Question', 'HCAHPS Answer Description', \n",
    "        'Footnote', 'Start Date', 'End Date'\n",
    "    ],\n",
    "    \"measure_prefixes\": [\n",
    "        'H_COMP_1', 'H_COMP_3', 'H_COMP_2', 'H_CLEAN_HSP',\n",
    "        'H_QUIET_HSP', 'H_COMP_5', 'H_COMP_6', 'H_HSP_RATING',\n",
    "        'H_RECMND', 'H_COMP_7'\n",
    "    ],\n",
    "    \"suffix_categories\": {\n",
    "        'Top-box Percentage': ['_A_P', '_Y_P', '_SA', '_DY', '_9_10'],\n",
    "        'Bottom-box Percentage': ['_SN_P', '_N_P', '_D_SD', '_DN', '_0_6'],\n",
    "        'Middle-box Percentage': ['_U_P', '_A', '_PY', '_7_8']\n",
    "    },\n",
    "    \"output_dir\": \"processed_data\"\n",
    "}\n",
    "\n",
    "def process_hcahps_data(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Process HCAHPS survey data from raw CSV to formatted analysis-ready format.\"\"\"\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    required_columns = {'HCAHPS Measure ID', 'HCAHPS Answer Percent'}\n",
    "    missing = required_columns - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    df.insert(0, 'Release Period', HCAHPS_CONFIG[\"release_period\"])\n",
    "    filtered = df.drop(columns=HCAHPS_CONFIG[\"columns_to_drop\"], errors=\"ignore\")\n",
    "\n",
    "    measure_pattern = f\"^({'|'.join(HCAHPS_CONFIG['measure_prefixes'])})_\"\n",
    "    mask = filtered['HCAHPS Measure ID'].str.match(measure_pattern, na=False)\n",
    "    filtered = filtered[mask].copy()\n",
    "\n",
    "    filtered['Measure ID'] = filtered['HCAHPS Measure ID'].str.extract(measure_pattern)[0]\n",
    "    \n",
    "    category_conditions = []\n",
    "    for category, suffixes in HCAHPS_CONFIG[\"suffix_categories\"].items():\n",
    "        pattern = f\"({'|'.join(suffixes)})$\"\n",
    "        category_conditions.append(filtered['HCAHPS Measure ID'].str.contains(pattern, na=False))\n",
    "    \n",
    "    filtered['Response Category'] = np.select(\n",
    "        category_conditions,\n",
    "        list(HCAHPS_CONFIG[\"suffix_categories\"].keys()),\n",
    "        default=pd.NA\n",
    "    )\n",
    "\n",
    "    filtered['HCAHPS Answer Percent'] = pd.to_numeric(\n",
    "        filtered['HCAHPS Answer Percent'], \n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    pivot_index = ['Release Period', 'Measure ID']\n",
    "    if 'State' in filtered.columns:\n",
    "        pivot_index.insert(1, 'State')\n",
    "\n",
    "    pivot_df = filtered.pivot_table(\n",
    "        index=pivot_index,\n",
    "        columns='Response Category',\n",
    "        values='HCAHPS Answer Percent',\n",
    "        aggfunc='mean',\n",
    "        fill_value=0\n",
    "    ).reset_index().rename_axis(columns=None)\n",
    "\n",
    "    percent_columns = list(HCAHPS_CONFIG[\"suffix_categories\"].keys())\n",
    "    for col in percent_columns:\n",
    "        if col in pivot_df.columns:\n",
    "            pivot_df[col] = pivot_df[col].clip(0, 100).astype(int)\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pivot_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return pivot_df\n",
    "\n",
    "# Configuration for data merging pipeline\n",
    "PIPELINE_CONFIG = {\n",
    "    \"base_dir\": None,  # To be set in main\n",
    "    \"data_paths\": {\n",
    "        \"state_results\": \"maven_data/state_results.csv\",\n",
    "        \"national_results\": \"maven_data/national_results.csv\",\n",
    "        \"state_2024\": \"healps_data/processed_data/state_2024.csv\",\n",
    "        \"national_2024\": \"healps_data/processed_data/national_2024.csv\",\n",
    "        \"states\": \"maven_data/states.csv\",\n",
    "        \"measures\": \"maven_data/measures.csv\",\n",
    "        \"reports\": \"maven_data/reports.csv\",\n",
    "    },\n",
    "    \"merge_keys\": {\n",
    "        \"state_merge\": [\"State\"],\n",
    "        \"measure_merge\": [\"Measure ID\"],\n",
    "        \"report_merge\": [\"Release Period\"],\n",
    "        \"covid_merge\": [\"Year\", \"State\"]\n",
    "    },\n",
    "    \"output_file\": \"final_merged_dataset.csv\"\n",
    "}\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Data processing pipeline for merging multiple healthcare datasets\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self._validate_paths()\n",
    "        \n",
    "    def _validate_paths(self) -> None:\n",
    "        \"\"\"Validate existence of all required data files\"\"\"\n",
    "        for key, rel_path in PIPELINE_CONFIG[\"data_paths\"].items():\n",
    "            path = PIPELINE_CONFIG[\"base_dir\"] / rel_path\n",
    "            if not path.exists():\n",
    "                raise FileNotFoundError(f\"Missing data file: {path}\")\n",
    "            PIPELINE_CONFIG[\"data_paths\"][key] = path\n",
    "\n",
    "    def load_data(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Load all required datasets with validation\"\"\"\n",
    "        datasets = {}\n",
    "        required_columns = {\n",
    "            \"state_results\": [\"State\", \"Measure ID\", \"Release Period\"],\n",
    "            \"national_results\": [\"Measure ID\", \"Release Period\"],\n",
    "            \"states\": [\"State\", \"State Name\"],\n",
    "            \"measures\": [\"Measure ID\", \"Measure\"]\n",
    "        }\n",
    "\n",
    "        for key, path in PIPELINE_CONFIG[\"data_paths\"].items():\n",
    "            datasets[key] = pd.read_csv(path)\n",
    "            if key in required_columns:\n",
    "                missing = set(required_columns[key]) - set(datasets[key].columns)\n",
    "                if missing:\n",
    "                    raise ValueError(f\"Missing columns in {key}: {missing}\")\n",
    "\n",
    "        return datasets\n",
    "\n",
    "    def _safe_concat(self, df1: pd.DataFrame, df2: pd.DataFrame, dataset: str) -> pd.DataFrame:\n",
    "        \"\"\"Helper function for safe dataframe concatenation\"\"\"\n",
    "        if df1.empty:\n",
    "            return df2.copy()\n",
    "        if df2.empty:\n",
    "            return df1.copy()\n",
    "        \n",
    "        if set(df1.columns) != set(df2.columns):\n",
    "            raise ValueError(f\"Column mismatch in {dataset} concatenation\")\n",
    "            \n",
    "        return pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    def merge_datasets(self, datasets: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"Main data merging pipeline\"\"\"\n",
    "        state_results = self._safe_concat(\n",
    "            datasets[\"state_results\"], \n",
    "            datasets[\"state_2024\"],\n",
    "            \"state results\"\n",
    "        )\n",
    "        \n",
    "        national_results = self._safe_concat(\n",
    "            datasets[\"national_results\"], \n",
    "            datasets[\"national_2024\"],\n",
    "            \"national results\"\n",
    "        )\n",
    "\n",
    "        merged = state_results.merge(\n",
    "            datasets[\"states\"],\n",
    "            on=PIPELINE_CONFIG[\"merge_keys\"][\"state_merge\"],\n",
    "            how=\"left\",\n",
    "            validate=\"m:1\"\n",
    "        ).merge(\n",
    "            datasets[\"measures\"],\n",
    "            on=PIPELINE_CONFIG[\"merge_keys\"][\"measure_merge\"],\n",
    "            how=\"left\",\n",
    "            validate=\"m:1\"\n",
    "        ).merge(\n",
    "            datasets[\"reports\"],\n",
    "            on=PIPELINE_CONFIG[\"merge_keys\"][\"report_merge\"],\n",
    "            how=\"left\",\n",
    "            validate=\"m:1\"\n",
    "        )\n",
    "\n",
    "        merged = merged.merge(\n",
    "            national_results,\n",
    "            on=PIPELINE_CONFIG[\"merge_keys\"][\"report_merge\"] + PIPELINE_CONFIG[\"merge_keys\"][\"measure_merge\"],\n",
    "            how=\"left\",\n",
    "            suffixes=('', '_national'),\n",
    "            validate=\"m:1\"\n",
    "        )\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def save_results(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Save final merged dataset\"\"\"\n",
    "        output_path = PIPELINE_CONFIG[\"base_dir\"] / PIPELINE_CONFIG[\"output_file\"]\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "    def run_pipeline(self) -> None:\n",
    "        \"\"\"Execute full data processing pipeline\"\"\"\n",
    "        datasets = self.load_data()\n",
    "        merged_data = self.merge_datasets(datasets)\n",
    "        self.save_results(merged_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        base_dir = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        base_dir = Path.cwd().parent\n",
    "\n",
    "    PIPELINE_CONFIG[\"base_dir\"] = base_dir\n",
    "\n",
    "    # Process HCAHPS data\n",
    "    input_files = [\n",
    "        base_dir / \"healps_data\" / \"HCAHPS-National.csv\",\n",
    "        base_dir / \"healps_data\" / \"HCAHPS-State.csv\"\n",
    "    ]\n",
    "    output_dir = base_dir / \"healps_data\" / HCAHPS_CONFIG[\"output_dir\"]\n",
    "    output_files = [\n",
    "        output_dir / \"national_2024.csv\",\n",
    "        output_dir / \"state_2024.csv\"\n",
    "    ]\n",
    "\n",
    "    for path in input_files:\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Missing input file: {path}\")\n",
    "\n",
    "    for input_path, output_path in zip(input_files, output_files):\n",
    "        process_hcahps_data(input_path, output_path)\n",
    "\n",
    "    # Run merging pipeline\n",
    "    pipeline = DataPipeline()\n",
    "    pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG = {\n",
    "    \"release_period\": \"07_2024\",\n",
    "    \"columns_to_drop\": [\n",
    "        'HCAHPS Question', 'HCAHPS Answer Description',\n",
    "        'Footnote', 'Start Date', 'End Date'\n",
    "    ],\n",
    "    \"measure_prefixes\": [\n",
    "        'H_COMP_1','H_COMP_2','H_COMP_3','H_CLEAN_HSP',\n",
    "        'H_QUIET_HSP','H_COMP_5','H_COMP_6',\n",
    "        'H_HSP_RATING','H_RECMND','H_COMP_7'\n",
    "    ],\n",
    "    \"suffix_categories\": {\n",
    "        'Top-box Percentage':    ['_A_P','_Y_P','_SA','_DY','_9_10'],\n",
    "        'Bottom-box Percentage': ['_SN_P','_N_P','_D_SD','_DN','_0_6'],\n",
    "        'Middle-box Percentage': ['_U_P','_A','_PY','_7_8']\n",
    "    },\n",
    "    \"raw_data_dir\": Path(\"../data/hcahps_data\"),\n",
    "    \"processed_data_dir\": Path(\"../data/hcahps_data/processed_data\"),\n",
    "    \"processed_national\": \"national_2024.csv\",\n",
    "    \"processed_state\": \"state_2024.csv\",\n",
    "    \"maven_data_dir\": Path(\"../data/maven_data\"),\n",
    "    \"final_merged_file\": Path(\"../data/final_merged_dataset.csv\"),\n",
    "    \"merge_keys\": {\n",
    "        \"state_merge\": [\"State\"],\n",
    "        \"measure_merge\": [\"Measure ID\"],\n",
    "        \"report_merge\": [\"Release Period\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "def process_hcahps_data(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(input_path)\n",
    "    df.insert(0, 'Release Period', CONFIG[\"release_period\"])\n",
    "    df.drop(columns=CONFIG[\"columns_to_drop\"], errors='ignore', inplace=True)\n",
    "    measure_regex = f\"^({'|'.join(CONFIG['measure_prefixes'])})_\"\n",
    "    df = df[df['HCAHPS Measure ID'].str.match(measure_regex, na=False)].copy()\n",
    "    df['Measure ID'] = df['HCAHPS Measure ID'].str.extract(measure_regex)[0]\n",
    "\n",
    "    cat_conditions = []\n",
    "    for cat, suffixes in CONFIG[\"suffix_categories\"].items():\n",
    "        cat_conditions.append(df['HCAHPS Measure ID'].str.contains(f\"(?:{'|'.join(suffixes)})$\", na=False))\n",
    "        \n",
    "    df['Response Category'] = np.select(cat_conditions, CONFIG[\"suffix_categories\"].keys(), default=pd.NA)\n",
    "    df['HCAHPS Answer Percent'] = pd.to_numeric(df['HCAHPS Answer Percent'], errors='coerce')\n",
    "\n",
    "    pivot_index = ['Release Period','Measure ID']\n",
    "    if 'State' in df.columns:\n",
    "        pivot_index.insert(1, 'State')\n",
    "\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=pivot_index,\n",
    "        columns='Response Category',\n",
    "        values='HCAHPS Answer Percent',\n",
    "        aggfunc='mean',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    pivot_df.columns.name = None\n",
    "\n",
    "    for cat in CONFIG[\"suffix_categories\"].keys():\n",
    "        if cat in pivot_df.columns:\n",
    "            pivot_df[cat] = pivot_df[cat].clip(0, 100).astype(int)\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pivot_df.to_csv(output_path, index=False)\n",
    "    return pivot_df\n",
    "\n",
    "def safe_concat(df1: pd.DataFrame, df2: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df1.empty:\n",
    "        return df2.copy()\n",
    "    if df2.empty:\n",
    "        return df1.copy()\n",
    "    if set(df1.columns) != set(df2.columns):\n",
    "        raise ValueError(\"Cannot concatenate; columns differ.\")\n",
    "    return pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "def merge_datasets(maven_data: dict, new_state: pd.DataFrame, new_national: pd.DataFrame) -> pd.DataFrame:\n",
    "    state_results = safe_concat(maven_data[\"state_results\"], new_state)\n",
    "    national_results = safe_concat(maven_data[\"national_results\"], new_national)\n",
    "    merged = (\n",
    "        state_results\n",
    "        .merge(maven_data[\"states\"],   on=CONFIG[\"merge_keys\"][\"state_merge\"],   how=\"left\", validate=\"m:1\")\n",
    "        .merge(maven_data[\"measures\"], on=CONFIG[\"merge_keys\"][\"measure_merge\"], how=\"left\", validate=\"m:1\")\n",
    "        .merge(maven_data[\"reports\"],  on=CONFIG[\"merge_keys\"][\"report_merge\"],  how=\"left\", validate=\"m:1\")\n",
    "    )\n",
    "    final = merged.merge(\n",
    "        national_results,\n",
    "        on=CONFIG[\"merge_keys\"][\"report_merge\"] + CONFIG[\"merge_keys\"][\"measure_merge\"],\n",
    "        how=\"left\",\n",
    "        suffixes=('', '_national'),\n",
    "        validate=\"m:1\"\n",
    "    )\n",
    "    return final\n",
    "\n",
    "def run_pipeline():\n",
    "    national_input = CONFIG[\"raw_data_dir\"] / \"HCAHPS-National.csv\"\n",
    "    state_input    = CONFIG[\"raw_data_dir\"] / \"HCAHPS-State.csv\"\n",
    "    national_out   = CONFIG[\"processed_data_dir\"] / CONFIG[\"processed_national\"]\n",
    "    state_out      = CONFIG[\"processed_data_dir\"] / CONFIG[\"processed_state\"]\n",
    "\n",
    "    national_df = process_hcahps_data(national_input, national_out)\n",
    "    state_df    = process_hcahps_data(state_input,    state_out)\n",
    "\n",
    "    maven_dir = CONFIG[\"maven_data_dir\"]\n",
    "    maven_data = {\n",
    "        \"state_results\":    pd.read_csv(maven_dir / \"state_results.csv\"),\n",
    "        \"national_results\": pd.read_csv(maven_dir / \"national_results.csv\"),\n",
    "        \"states\":           pd.read_csv(maven_dir / \"states.csv\"),\n",
    "        \"measures\":         pd.read_csv(maven_dir / \"measures.csv\"),\n",
    "        \"reports\":          pd.read_csv(maven_dir / \"reports.csv\")\n",
    "    }\n",
    "\n",
    "    final_merged = merge_datasets(maven_data, state_df, national_df)\n",
    "    final_out = CONFIG[\"final_merged_file\"]\n",
    "    final_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    final_merged.to_csv(final_out, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
